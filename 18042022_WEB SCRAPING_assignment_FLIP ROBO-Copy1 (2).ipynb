{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "feb678a3",
   "metadata": {},
   "source": [
    "# 1. Write a python program to display all the header tags from wikipedia.org.\n",
    "\n",
    "## Ans  ↓↓↓   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f40e211",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Welcome to Wikipedia'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_heading = soup.find('span',class_=\"mw-headline\")\n",
    "first_heading.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f1027a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Welcome to Wikipedia',\n",
       " \"From today's featured article\",\n",
       " 'Did you know\\xa0...',\n",
       " 'In the news',\n",
       " 'On this day',\n",
       " \"Today's featured picture\",\n",
       " 'Other areas of Wikipedia',\n",
       " \"Wikipedia's sister projects\",\n",
       " 'Wikipedia languages']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heading=[]\n",
    "\n",
    "for i in soup.find_all('span',class_=\"mw-headline\"):\n",
    "    heading.append(i.text)\n",
    "    \n",
    "heading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa83652d",
   "metadata": {},
   "source": [
    "# 2) Write a python program to display IMDB’s Top rated 100 movies’ data (i.e. name, rating, year of release) and make data frame.\n",
    "\n",
    "## Ans  ↓↓↓"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "490803d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page = requests.get('https://www.imdb.com/search/title/?groups=top_100&sort=user_rating,desc')\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0d0a9803",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<h3 class=\"lister-item-header\">\n",
       "<span class=\"lister-item-index unbold text-primary\">1.</span>\n",
       "<a href=\"/title/tt0111161/\">The Shawshank Redemption</a>\n",
       "<span class=\"lister-item-year text-muted unbold\">(1994)</span>\n",
       "</h3>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_moviename = soup.find('h3',class_=\"lister-item-header\")\n",
    "first_moviename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a75b9ceb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' 1. The Shawshank Redemption (1994) '"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_moviename = soup.find('h3',class_=\"lister-item-header\")\n",
    "first_moviename.text.replace(\"\\n\",\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b574db04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1.The Shawshank Redemption(1994)',\n",
       " '2.The Godfather(1972)',\n",
       " '3.The Dark Knight(2008)',\n",
       " '4.The Lord of the Rings: The Return of the King(2003)',\n",
       " \"5.Schindler's List(1993)\",\n",
       " '6.The Godfather: Part II(1974)',\n",
       " '7.12 Angry Men(1957)',\n",
       " '8.Pulp Fiction(1994)',\n",
       " '9.Everything Everywhere All at Once(2022)',\n",
       " '10.Inception(2010)',\n",
       " '11.The Lord of the Rings: The Two Towers(2002)',\n",
       " '12.Fight Club(1999)',\n",
       " '13.The Lord of the Rings: The Fellowship of the Ring(2001)',\n",
       " '14.Forrest Gump(1994)',\n",
       " '15.Il buono, il brutto, il cattivo(1966)',\n",
       " '16.The Matrix(1999)',\n",
       " '17.Goodfellas(1990)',\n",
       " '18.The Empire Strikes Back(1980)',\n",
       " \"19.One Flew Over the Cuckoo's Nest(1975)\",\n",
       " '20.Interstellar(2014)',\n",
       " '21.Cidade de Deus(2002)',\n",
       " '22.Sen to Chihiro no kamikakushi(2001)',\n",
       " '23.Saving Private Ryan(1998)',\n",
       " '24.The Green Mile(1999)',\n",
       " '25.La vita è bella(1997)',\n",
       " '26.Se7en(1995)',\n",
       " '27.Terminator 2: Judgment Day(1991)',\n",
       " '28.The Silence of the Lambs(1991)',\n",
       " '29.Star Wars(1977)',\n",
       " '30.Seppuku(1962)',\n",
       " '31.Shichinin no samurai(1954)',\n",
       " \"32.It's a Wonderful Life(1946)\",\n",
       " '33.Gisaengchung(2019)',\n",
       " '34.Whiplash(2014)',\n",
       " '35.The Intouchables(2011)',\n",
       " '36.The Prestige(2006)',\n",
       " '37.The Departed(2006)',\n",
       " '38.The Pianist(2002)',\n",
       " '39.Gladiator(2000)',\n",
       " '40.American History X(1998)',\n",
       " '41.The Usual Suspects(1995)',\n",
       " '42.Léon(1994)',\n",
       " '43.The Lion King(1994)',\n",
       " '44.Nuovo Cinema Paradiso(1988)',\n",
       " '45.Hotaru no haka(1988)',\n",
       " '46.Back to the Future(1985)',\n",
       " '47.Apocalypse Now(1979)',\n",
       " '48.Alien(1979)',\n",
       " '49.Once Upon a Time in the West(1968)',\n",
       " '50.Psycho(1960)']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movienames=[]\n",
    "\n",
    "for i in soup.find_all('h3',class_=\"lister-item-header\"):\n",
    "    movienames.append(i.text.replace(\"\\n\",\"\"))\n",
    "    \n",
    "movienames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "23b563e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<div class=\"inline-block ratings-imdb-rating\" data-value=\"9.3\" name=\"ir\">\n",
       "<span class=\"global-sprite rating-star imdb-rating\"></span>\n",
       "<strong>9.3</strong>\n",
       "</div>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_movierating = soup.find('div',class_=\"inline-block ratings-imdb-rating\")\n",
    "first_movierating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b33ffdca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'9.3'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_movierating = soup.find('div',class_=\"inline-block ratings-imdb-rating\")\n",
    "first_movierating.text.replace(\"\\n\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "04d14b86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['9.3',\n",
       " '9.2',\n",
       " '9.0',\n",
       " '9.0',\n",
       " '9.0',\n",
       " '9.0',\n",
       " '9.0',\n",
       " '8.9',\n",
       " '8.8',\n",
       " '8.8',\n",
       " '8.8',\n",
       " '8.8',\n",
       " '8.8',\n",
       " '8.8',\n",
       " '8.8',\n",
       " '8.7',\n",
       " '8.7',\n",
       " '8.7',\n",
       " '8.7',\n",
       " '8.6',\n",
       " '8.6',\n",
       " '8.6',\n",
       " '8.6',\n",
       " '8.6',\n",
       " '8.6',\n",
       " '8.6',\n",
       " '8.6',\n",
       " '8.6',\n",
       " '8.6',\n",
       " '8.6',\n",
       " '8.6',\n",
       " '8.6',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movieratings=[]\n",
    "\n",
    "for i in soup.find_all('div',class_=\"inline-block ratings-imdb-rating\"):\n",
    "    movieratings.append(i.text.replace(\"\\n\",\"\"))\n",
    "    \n",
    "movieratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8e064ba2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<span class=\"lister-item-year text-muted unbold\">(1994)</span>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "release_year = soup.find('span',class_=\"lister-item-year text-muted unbold\")\n",
    "release_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "621e7089",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(1994)'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "release_year.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ce3bab64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['(1994)',\n",
       " '(1972)',\n",
       " '(2008)',\n",
       " '(2003)',\n",
       " '(1993)',\n",
       " '(1974)',\n",
       " '(1957)',\n",
       " '(1994)',\n",
       " '(2022)',\n",
       " '(2010)',\n",
       " '(2002)',\n",
       " '(1999)',\n",
       " '(2001)',\n",
       " '(1994)',\n",
       " '(1966)',\n",
       " '(1999)',\n",
       " '(1990)',\n",
       " '(1980)',\n",
       " '(1975)',\n",
       " '(2014)',\n",
       " '(2002)',\n",
       " '(2001)',\n",
       " '(1998)',\n",
       " '(1999)',\n",
       " '(1997)',\n",
       " '(1995)',\n",
       " '(1991)',\n",
       " '(1991)',\n",
       " '(1977)',\n",
       " '(1962)',\n",
       " '(1954)',\n",
       " '(1946)',\n",
       " '(2019)',\n",
       " '(2014)',\n",
       " '(2011)',\n",
       " '(2006)',\n",
       " '(2006)',\n",
       " '(2002)',\n",
       " '(2000)',\n",
       " '(1998)',\n",
       " '(1995)',\n",
       " '(1994)',\n",
       " '(1994)',\n",
       " '(1988)',\n",
       " '(1988)',\n",
       " '(1985)',\n",
       " '(1979)',\n",
       " '(1979)',\n",
       " '(1968)',\n",
       " '(1960)']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "release_year=[]\n",
    "\n",
    "for i in soup.find_all('span',class_=\"lister-item-year text-muted unbold\"):\n",
    "    release_year.append(i.text)\n",
    "    \n",
    "release_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4bf344c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 50 50\n"
     ]
    }
   ],
   "source": [
    "## pricing length\n",
    "\n",
    "print(len(movienames),len(movieratings),len(release_year))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "83904608",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Movienames</th>\n",
       "      <th>Movieratings</th>\n",
       "      <th>release_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.The Shawshank Redemption(1994)</td>\n",
       "      <td>9.3</td>\n",
       "      <td>(1994)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.The Godfather(1972)</td>\n",
       "      <td>9.2</td>\n",
       "      <td>(1972)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.The Dark Knight(2008)</td>\n",
       "      <td>9.0</td>\n",
       "      <td>(2008)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.The Lord of the Rings: The Return of the Kin...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>(2003)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.Schindler's List(1993)</td>\n",
       "      <td>9.0</td>\n",
       "      <td>(1993)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.The Godfather: Part II(1974)</td>\n",
       "      <td>9.0</td>\n",
       "      <td>(1974)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.12 Angry Men(1957)</td>\n",
       "      <td>9.0</td>\n",
       "      <td>(1957)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.Pulp Fiction(1994)</td>\n",
       "      <td>8.9</td>\n",
       "      <td>(1994)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.Everything Everywhere All at Once(2022)</td>\n",
       "      <td>8.8</td>\n",
       "      <td>(2022)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.Inception(2010)</td>\n",
       "      <td>8.8</td>\n",
       "      <td>(2010)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11.The Lord of the Rings: The Two Towers(2002)</td>\n",
       "      <td>8.8</td>\n",
       "      <td>(2002)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12.Fight Club(1999)</td>\n",
       "      <td>8.8</td>\n",
       "      <td>(1999)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13.The Lord of the Rings: The Fellowship of th...</td>\n",
       "      <td>8.8</td>\n",
       "      <td>(2001)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14.Forrest Gump(1994)</td>\n",
       "      <td>8.8</td>\n",
       "      <td>(1994)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15.Il buono, il brutto, il cattivo(1966)</td>\n",
       "      <td>8.8</td>\n",
       "      <td>(1966)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16.The Matrix(1999)</td>\n",
       "      <td>8.7</td>\n",
       "      <td>(1999)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17.Goodfellas(1990)</td>\n",
       "      <td>8.7</td>\n",
       "      <td>(1990)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18.The Empire Strikes Back(1980)</td>\n",
       "      <td>8.7</td>\n",
       "      <td>(1980)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19.One Flew Over the Cuckoo's Nest(1975)</td>\n",
       "      <td>8.7</td>\n",
       "      <td>(1975)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20.Interstellar(2014)</td>\n",
       "      <td>8.6</td>\n",
       "      <td>(2014)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21.Cidade de Deus(2002)</td>\n",
       "      <td>8.6</td>\n",
       "      <td>(2002)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22.Sen to Chihiro no kamikakushi(2001)</td>\n",
       "      <td>8.6</td>\n",
       "      <td>(2001)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23.Saving Private Ryan(1998)</td>\n",
       "      <td>8.6</td>\n",
       "      <td>(1998)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24.The Green Mile(1999)</td>\n",
       "      <td>8.6</td>\n",
       "      <td>(1999)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25.La vita è bella(1997)</td>\n",
       "      <td>8.6</td>\n",
       "      <td>(1997)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26.Se7en(1995)</td>\n",
       "      <td>8.6</td>\n",
       "      <td>(1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27.Terminator 2: Judgment Day(1991)</td>\n",
       "      <td>8.6</td>\n",
       "      <td>(1991)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28.The Silence of the Lambs(1991)</td>\n",
       "      <td>8.6</td>\n",
       "      <td>(1991)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29.Star Wars(1977)</td>\n",
       "      <td>8.6</td>\n",
       "      <td>(1977)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30.Seppuku(1962)</td>\n",
       "      <td>8.6</td>\n",
       "      <td>(1962)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31.Shichinin no samurai(1954)</td>\n",
       "      <td>8.6</td>\n",
       "      <td>(1954)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32.It's a Wonderful Life(1946)</td>\n",
       "      <td>8.6</td>\n",
       "      <td>(1946)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33.Gisaengchung(2019)</td>\n",
       "      <td>8.5</td>\n",
       "      <td>(2019)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>34.Whiplash(2014)</td>\n",
       "      <td>8.5</td>\n",
       "      <td>(2014)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>35.The Intouchables(2011)</td>\n",
       "      <td>8.5</td>\n",
       "      <td>(2011)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>36.The Prestige(2006)</td>\n",
       "      <td>8.5</td>\n",
       "      <td>(2006)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>37.The Departed(2006)</td>\n",
       "      <td>8.5</td>\n",
       "      <td>(2006)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>38.The Pianist(2002)</td>\n",
       "      <td>8.5</td>\n",
       "      <td>(2002)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>39.Gladiator(2000)</td>\n",
       "      <td>8.5</td>\n",
       "      <td>(2000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>40.American History X(1998)</td>\n",
       "      <td>8.5</td>\n",
       "      <td>(1998)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>41.The Usual Suspects(1995)</td>\n",
       "      <td>8.5</td>\n",
       "      <td>(1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>42.Léon(1994)</td>\n",
       "      <td>8.5</td>\n",
       "      <td>(1994)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>43.The Lion King(1994)</td>\n",
       "      <td>8.5</td>\n",
       "      <td>(1994)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>44.Nuovo Cinema Paradiso(1988)</td>\n",
       "      <td>8.5</td>\n",
       "      <td>(1988)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>45.Hotaru no haka(1988)</td>\n",
       "      <td>8.5</td>\n",
       "      <td>(1988)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>46.Back to the Future(1985)</td>\n",
       "      <td>8.5</td>\n",
       "      <td>(1985)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>47.Apocalypse Now(1979)</td>\n",
       "      <td>8.5</td>\n",
       "      <td>(1979)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>48.Alien(1979)</td>\n",
       "      <td>8.5</td>\n",
       "      <td>(1979)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>49.Once Upon a Time in the West(1968)</td>\n",
       "      <td>8.5</td>\n",
       "      <td>(1968)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>50.Psycho(1960)</td>\n",
       "      <td>8.5</td>\n",
       "      <td>(1960)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Movienames Movieratings  \\\n",
       "0                    1.The Shawshank Redemption(1994)          9.3   \n",
       "1                               2.The Godfather(1972)          9.2   \n",
       "2                             3.The Dark Knight(2008)          9.0   \n",
       "3   4.The Lord of the Rings: The Return of the Kin...          9.0   \n",
       "4                            5.Schindler's List(1993)          9.0   \n",
       "5                      6.The Godfather: Part II(1974)          9.0   \n",
       "6                                7.12 Angry Men(1957)          9.0   \n",
       "7                                8.Pulp Fiction(1994)          8.9   \n",
       "8           9.Everything Everywhere All at Once(2022)          8.8   \n",
       "9                                  10.Inception(2010)          8.8   \n",
       "10     11.The Lord of the Rings: The Two Towers(2002)          8.8   \n",
       "11                                12.Fight Club(1999)          8.8   \n",
       "12  13.The Lord of the Rings: The Fellowship of th...          8.8   \n",
       "13                              14.Forrest Gump(1994)          8.8   \n",
       "14           15.Il buono, il brutto, il cattivo(1966)          8.8   \n",
       "15                                16.The Matrix(1999)          8.7   \n",
       "16                                17.Goodfellas(1990)          8.7   \n",
       "17                   18.The Empire Strikes Back(1980)          8.7   \n",
       "18           19.One Flew Over the Cuckoo's Nest(1975)          8.7   \n",
       "19                              20.Interstellar(2014)          8.6   \n",
       "20                            21.Cidade de Deus(2002)          8.6   \n",
       "21             22.Sen to Chihiro no kamikakushi(2001)          8.6   \n",
       "22                       23.Saving Private Ryan(1998)          8.6   \n",
       "23                            24.The Green Mile(1999)          8.6   \n",
       "24                           25.La vita è bella(1997)          8.6   \n",
       "25                                     26.Se7en(1995)          8.6   \n",
       "26                27.Terminator 2: Judgment Day(1991)          8.6   \n",
       "27                  28.The Silence of the Lambs(1991)          8.6   \n",
       "28                                 29.Star Wars(1977)          8.6   \n",
       "29                                   30.Seppuku(1962)          8.6   \n",
       "30                      31.Shichinin no samurai(1954)          8.6   \n",
       "31                     32.It's a Wonderful Life(1946)          8.6   \n",
       "32                              33.Gisaengchung(2019)          8.5   \n",
       "33                                  34.Whiplash(2014)          8.5   \n",
       "34                          35.The Intouchables(2011)          8.5   \n",
       "35                              36.The Prestige(2006)          8.5   \n",
       "36                              37.The Departed(2006)          8.5   \n",
       "37                               38.The Pianist(2002)          8.5   \n",
       "38                                 39.Gladiator(2000)          8.5   \n",
       "39                        40.American History X(1998)          8.5   \n",
       "40                        41.The Usual Suspects(1995)          8.5   \n",
       "41                                      42.Léon(1994)          8.5   \n",
       "42                             43.The Lion King(1994)          8.5   \n",
       "43                     44.Nuovo Cinema Paradiso(1988)          8.5   \n",
       "44                            45.Hotaru no haka(1988)          8.5   \n",
       "45                        46.Back to the Future(1985)          8.5   \n",
       "46                            47.Apocalypse Now(1979)          8.5   \n",
       "47                                     48.Alien(1979)          8.5   \n",
       "48              49.Once Upon a Time in the West(1968)          8.5   \n",
       "49                                    50.Psycho(1960)          8.5   \n",
       "\n",
       "   release_year  \n",
       "0        (1994)  \n",
       "1        (1972)  \n",
       "2        (2008)  \n",
       "3        (2003)  \n",
       "4        (1993)  \n",
       "5        (1974)  \n",
       "6        (1957)  \n",
       "7        (1994)  \n",
       "8        (2022)  \n",
       "9        (2010)  \n",
       "10       (2002)  \n",
       "11       (1999)  \n",
       "12       (2001)  \n",
       "13       (1994)  \n",
       "14       (1966)  \n",
       "15       (1999)  \n",
       "16       (1990)  \n",
       "17       (1980)  \n",
       "18       (1975)  \n",
       "19       (2014)  \n",
       "20       (2002)  \n",
       "21       (2001)  \n",
       "22       (1998)  \n",
       "23       (1999)  \n",
       "24       (1997)  \n",
       "25       (1995)  \n",
       "26       (1991)  \n",
       "27       (1991)  \n",
       "28       (1977)  \n",
       "29       (1962)  \n",
       "30       (1954)  \n",
       "31       (1946)  \n",
       "32       (2019)  \n",
       "33       (2014)  \n",
       "34       (2011)  \n",
       "35       (2006)  \n",
       "36       (2006)  \n",
       "37       (2002)  \n",
       "38       (2000)  \n",
       "39       (1998)  \n",
       "40       (1995)  \n",
       "41       (1994)  \n",
       "42       (1994)  \n",
       "43       (1988)  \n",
       "44       (1988)  \n",
       "45       (1985)  \n",
       "46       (1979)  \n",
       "47       (1979)  \n",
       "48       (1968)  \n",
       "49       (1960)  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Making data frame\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({'Movienames':movienames,'Movieratings':movieratings,'release_year':release_year})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce9ae299",
   "metadata": {},
   "source": [
    "# 3) Write a python program to display IMDB’s Top rated 100 Indian movies’ data (i.e. name, rating, year of #release) and make data frame.\n",
    "\n",
    "## Ans  ↓↓↓\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f5b2bcbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page = requests.get('https://www.imdb.com/india/top-rated-indian-movies/')\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3fe29890",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<td class=\"titleColumn\">\n",
       "      1.\n",
       "      <a href=\"/title/tt15097216/\" title=\"T.J. Gnanavel (dir.), Suriya, Lijo Mol Jose\">Jai Bhim</a>\n",
       "<span class=\"secondaryInfo\">(2021)</span>\n",
       "</td>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_movie = soup.find('td',class_=\"titleColumn\")\n",
    "first_movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6fcfae12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n      1.\\n      Jai Bhim\\n(2021)\\n'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_movie = soup.find('td',class_=\"titleColumn\")\n",
    "first_movie.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3f23c3f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'       1.       Jai Bhim (2021) '"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_movie = soup.find('td',class_=\"titleColumn\")\n",
    "first_movie.text.replace(\"\\n\",\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "313476ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<td class=\"ratingColumn imdbRating\">\n",
       "<strong title=\"8.4 based on 187,237 user ratings\">8.4</strong>\n",
       "</td>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movierating = soup.find('td',class_=\"ratingColumn imdbRating\")\n",
    "movierating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b984e7a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n8.4\\n'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movierating = soup.find('td',class_=\"ratingColumn imdbRating\")\n",
    "movierating.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8bc1ff41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' 8.4 '"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movierating = soup.find('td',class_=\"ratingColumn imdbRating\")\n",
    "movierating.text.replace(\"\\n\",\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d2f9273c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' 8.4 ',\n",
       " ' 8.4 ',\n",
       " ' 8.4 ',\n",
       " ' 8.4 ',\n",
       " ' 8.4 ',\n",
       " ' 8.4 ',\n",
       " ' 8.4 ',\n",
       " ' 8.3 ',\n",
       " ' 8.3 ',\n",
       " ' 8.3 ',\n",
       " ' 8.3 ',\n",
       " ' 8.3 ',\n",
       " ' 8.3 ',\n",
       " ' 8.3 ',\n",
       " ' 8.3 ',\n",
       " ' 8.3 ',\n",
       " ' 8.3 ',\n",
       " ' 8.3 ',\n",
       " ' 8.3 ',\n",
       " ' 8.2 ',\n",
       " ' 8.2 ',\n",
       " ' 8.2 ',\n",
       " ' 8.2 ',\n",
       " ' 8.2 ',\n",
       " ' 8.2 ',\n",
       " ' 8.2 ',\n",
       " ' 8.2 ',\n",
       " ' 8.2 ',\n",
       " ' 8.2 ',\n",
       " ' 8.2 ',\n",
       " ' 8.2 ',\n",
       " ' 8.2 ',\n",
       " ' 8.2 ',\n",
       " ' 8.2 ',\n",
       " ' 8.1 ',\n",
       " ' 8.1 ',\n",
       " ' 8.1 ',\n",
       " ' 8.1 ',\n",
       " ' 8.1 ',\n",
       " ' 8.1 ',\n",
       " ' 8.1 ',\n",
       " ' 8.1 ',\n",
       " ' 8.1 ',\n",
       " ' 8.1 ',\n",
       " ' 8.1 ',\n",
       " ' 8.1 ',\n",
       " ' 8.1 ',\n",
       " ' 8.1 ',\n",
       " ' 8.1 ',\n",
       " ' 8.1 ',\n",
       " ' 8.1 ',\n",
       " ' 8.1 ',\n",
       " ' 8.1 ',\n",
       " ' 8.1 ',\n",
       " ' 8.1 ',\n",
       " ' 8.1 ',\n",
       " ' 8.1 ',\n",
       " ' 8.1 ',\n",
       " ' 8.1 ',\n",
       " ' 8.1 ',\n",
       " ' 8.1 ',\n",
       " ' 8.1 ',\n",
       " ' 8.1 ',\n",
       " ' 8.1 ',\n",
       " ' 8.1 ',\n",
       " ' 8.1 ',\n",
       " ' 8.1 ',\n",
       " ' 8.1 ',\n",
       " ' 8.1 ',\n",
       " ' 8.1 ',\n",
       " ' 8.1 ',\n",
       " ' 8.1 ',\n",
       " ' 8.1 ',\n",
       " ' 8.1 ',\n",
       " ' 8.1 ',\n",
       " ' 8.1 ',\n",
       " ' 8.0 ',\n",
       " ' 8.0 ',\n",
       " ' 8.0 ',\n",
       " ' 8.0 ',\n",
       " ' 8.0 ',\n",
       " ' 8.0 ',\n",
       " ' 8.0 ',\n",
       " ' 8.0 ',\n",
       " ' 8.0 ',\n",
       " ' 8.0 ',\n",
       " ' 8.0 ',\n",
       " ' 8.0 ',\n",
       " ' 8.0 ',\n",
       " ' 8.0 ',\n",
       " ' 8.0 ',\n",
       " ' 8.0 ',\n",
       " ' 8.0 ',\n",
       " ' 8.0 ',\n",
       " ' 8.0 ',\n",
       " ' 8.0 ',\n",
       " ' 8.0 ',\n",
       " ' 8.0 ',\n",
       " ' 8.0 ',\n",
       " ' 8.0 ',\n",
       " ' 8.0 ',\n",
       " ' 8.0 ',\n",
       " ' 8.0 ',\n",
       " ' 8.0 ',\n",
       " ' 8.0 ',\n",
       " ' 8.0 ',\n",
       " ' 8.0 ',\n",
       " ' 8.0 ',\n",
       " ' 8.0 ',\n",
       " ' 8.0 ',\n",
       " ' 8.0 ',\n",
       " ' 8.0 ',\n",
       " ' 8.0 ',\n",
       " ' 8.0 ',\n",
       " ' 8.0 ',\n",
       " ' 8.0 ',\n",
       " ' 8.0 ',\n",
       " ' 8.0 ',\n",
       " ' 8.0 ',\n",
       " ' 8.0 ',\n",
       " ' 8.0 ',\n",
       " ' 8.0 ',\n",
       " ' 8.0 ',\n",
       " ' 7.9 ',\n",
       " ' 7.9 ',\n",
       " ' 7.9 ',\n",
       " ' 7.9 ',\n",
       " ' 7.9 ',\n",
       " ' 7.9 ',\n",
       " ' 7.9 ',\n",
       " ' 7.9 ',\n",
       " ' 7.9 ',\n",
       " ' 7.9 ',\n",
       " ' 7.9 ',\n",
       " ' 7.9 ',\n",
       " ' 7.9 ',\n",
       " ' 7.9 ',\n",
       " ' 7.9 ',\n",
       " ' 7.9 ',\n",
       " ' 7.9 ',\n",
       " ' 7.9 ',\n",
       " ' 7.9 ',\n",
       " ' 7.9 ',\n",
       " ' 7.9 ',\n",
       " ' 7.9 ',\n",
       " ' 7.9 ',\n",
       " ' 7.9 ',\n",
       " ' 7.9 ',\n",
       " ' 7.9 ',\n",
       " ' 7.9 ',\n",
       " ' 7.9 ',\n",
       " ' 7.9 ',\n",
       " ' 7.9 ',\n",
       " ' 7.9 ',\n",
       " ' 7.9 ',\n",
       " ' 7.9 ',\n",
       " ' 7.8 ',\n",
       " ' 7.8 ',\n",
       " ' 7.8 ',\n",
       " ' 7.8 ',\n",
       " ' 7.8 ',\n",
       " ' 7.8 ',\n",
       " ' 7.8 ',\n",
       " ' 7.8 ',\n",
       " ' 7.8 ',\n",
       " ' 7.8 ',\n",
       " ' 7.8 ',\n",
       " ' 7.8 ',\n",
       " ' 7.8 ',\n",
       " ' 7.8 ',\n",
       " ' 7.8 ',\n",
       " ' 7.8 ',\n",
       " ' 7.8 ',\n",
       " ' 7.8 ',\n",
       " ' 7.8 ',\n",
       " ' 7.8 ',\n",
       " ' 7.8 ',\n",
       " ' 7.8 ',\n",
       " ' 7.8 ',\n",
       " ' 7.8 ',\n",
       " ' 7.8 ',\n",
       " ' 7.8 ',\n",
       " ' 7.8 ',\n",
       " ' 7.8 ',\n",
       " ' 7.8 ',\n",
       " ' 7.8 ',\n",
       " ' 7.8 ',\n",
       " ' 7.8 ',\n",
       " ' 7.8 ',\n",
       " ' 7.8 ',\n",
       " ' 7.8 ',\n",
       " ' 7.8 ',\n",
       " ' 7.8 ',\n",
       " ' 7.8 ',\n",
       " ' 7.7 ',\n",
       " ' 7.7 ',\n",
       " ' 7.7 ',\n",
       " ' 7.7 ',\n",
       " ' 7.7 ',\n",
       " ' 7.7 ',\n",
       " ' 7.7 ',\n",
       " ' 7.7 ',\n",
       " ' 7.7 ',\n",
       " ' 7.7 ',\n",
       " ' 7.7 ',\n",
       " ' 7.7 ',\n",
       " ' 7.7 ',\n",
       " ' 7.7 ',\n",
       " ' 7.7 ',\n",
       " ' 7.7 ',\n",
       " ' 7.7 ',\n",
       " ' 7.7 ',\n",
       " ' 7.7 ',\n",
       " ' 7.7 ',\n",
       " ' 7.7 ',\n",
       " ' 7.7 ',\n",
       " ' 7.7 ',\n",
       " ' 7.7 ',\n",
       " ' 7.7 ',\n",
       " ' 7.7 ',\n",
       " ' 7.7 ',\n",
       " ' 7.7 ',\n",
       " ' 7.7 ',\n",
       " ' 7.7 ',\n",
       " ' 7.7 ',\n",
       " ' 7.7 ',\n",
       " ' 7.7 ',\n",
       " ' 7.7 ',\n",
       " ' 7.7 ',\n",
       " ' 7.7 ',\n",
       " ' 7.7 ',\n",
       " ' 7.7 ',\n",
       " ' 7.7 ',\n",
       " ' 7.7 ',\n",
       " ' 7.6 ',\n",
       " ' 7.6 ',\n",
       " ' 7.6 ',\n",
       " ' 7.6 ',\n",
       " ' 7.6 ',\n",
       " ' 7.6 ',\n",
       " ' 7.6 ',\n",
       " ' 7.6 ',\n",
       " ' 7.6 ',\n",
       " ' 7.6 ',\n",
       " ' 7.6 ',\n",
       " ' 7.6 ',\n",
       " ' 7.6 ',\n",
       " ' 7.6 ',\n",
       " ' 7.6 ',\n",
       " ' 7.6 ']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movierating=[]\n",
    "\n",
    "for i in soup.find_all('td',class_=\"ratingColumn imdbRating\"):\n",
    "    movierating.append(i.text.replace(\"\\n\",\" \"))\n",
    "    \n",
    "movierating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ee58f89e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<span class=\"secondaryInfo\">(2021)</span>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_year = soup.find('span',class_=\"secondaryInfo\")\n",
    "r_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "868c8702",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(2021)'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_year = soup.find('span',class_=\"secondaryInfo\")\n",
    "r_year.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "55c4be49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['(2021)',\n",
       " '(2003)',\n",
       " '(2022)',\n",
       " '(1979)',\n",
       " '(1987)',\n",
       " '(2018)',\n",
       " '(1959)',\n",
       " '(2009)',\n",
       " '(1993)',\n",
       " '(2004)',\n",
       " '(2019)',\n",
       " '(2007)',\n",
       " '(2018)',\n",
       " '(2016)',\n",
       " '(2021)',\n",
       " '(1989)',\n",
       " '(2020)',\n",
       " '(2019)',\n",
       " '(1955)',\n",
       " '(2019)',\n",
       " '(1992)',\n",
       " '(2019)',\n",
       " '(2015)',\n",
       " '(2018)',\n",
       " '(1991)',\n",
       " '(2016)',\n",
       " '(2021)',\n",
       " '(2021)',\n",
       " '(2021)',\n",
       " '(1956)',\n",
       " '(2015)',\n",
       " '(1983)',\n",
       " '(2018)',\n",
       " '(2006)',\n",
       " '(1975)',\n",
       " '(2018)',\n",
       " '(2013)',\n",
       " '(2019)',\n",
       " '(2005)',\n",
       " '(2018)',\n",
       " '(1998)',\n",
       " '(2014)',\n",
       " '(2019)',\n",
       " '(2018)',\n",
       " '(2015)',\n",
       " '(2016)',\n",
       " '(1993)',\n",
       " '(2013)',\n",
       " '(2012)',\n",
       " '(2002)',\n",
       " '(2018)',\n",
       " '(1965)',\n",
       " '(2015)',\n",
       " '(1997)',\n",
       " '(1988)',\n",
       " '(2012)',\n",
       " '(2012)',\n",
       " '(2017)',\n",
       " '(2011)',\n",
       " '(2016)',\n",
       " '(2018)',\n",
       " '(1999)',\n",
       " '(1995)',\n",
       " '(2005)',\n",
       " '(2016)',\n",
       " '(1992)',\n",
       " '(2004)',\n",
       " '(2007)',\n",
       " '(2019)',\n",
       " '(2006)',\n",
       " '(2013)',\n",
       " '(2019)',\n",
       " '(2015)',\n",
       " '(1957)',\n",
       " '(2013)',\n",
       " '(2014)',\n",
       " '(2015)',\n",
       " '(2003)',\n",
       " '(2012)',\n",
       " '(2014)',\n",
       " '(2021)',\n",
       " '(2019)',\n",
       " '(2001)',\n",
       " '(1999)',\n",
       " '(2014)',\n",
       " '(2010)',\n",
       " '(2012)',\n",
       " '(1975)',\n",
       " '(2012)',\n",
       " '(2017)',\n",
       " '(2002)',\n",
       " '(1982)',\n",
       " '(2000)',\n",
       " '(2022)',\n",
       " '(2006)',\n",
       " '(1995)',\n",
       " '(2015)',\n",
       " '(2001)',\n",
       " '(2012)',\n",
       " '(2016)',\n",
       " '(2015)',\n",
       " '(1992)',\n",
       " '(2016)',\n",
       " '(2017)',\n",
       " '(2008)',\n",
       " '(2005)',\n",
       " '(2006)',\n",
       " '(2003)',\n",
       " '(2021)',\n",
       " '(2022)',\n",
       " '(1964)',\n",
       " '(1971)',\n",
       " '(2004)',\n",
       " '(2018)',\n",
       " '(2000)',\n",
       " '(2019)',\n",
       " '(2006)',\n",
       " '(2015)',\n",
       " '(1989)',\n",
       " '(1995)',\n",
       " '(2006)',\n",
       " '(2013)',\n",
       " '(2021)',\n",
       " '(2014)',\n",
       " '(1996)',\n",
       " '(1960)',\n",
       " '(2018)',\n",
       " '(1995)',\n",
       " '(2021)',\n",
       " '(2003)',\n",
       " '(2013)',\n",
       " '(2005)',\n",
       " '(1994)',\n",
       " '(2019)',\n",
       " '(2009)',\n",
       " '(1999)',\n",
       " '(2016)',\n",
       " '(2008)',\n",
       " '(2019)',\n",
       " '(2019)',\n",
       " '(1975)',\n",
       " '(2018)',\n",
       " '(2012)',\n",
       " '(2013)',\n",
       " '(1999)',\n",
       " '(2016)',\n",
       " '(2002)',\n",
       " '(1968)',\n",
       " '(2019)',\n",
       " '(2014)',\n",
       " '(2017)',\n",
       " '(2011)',\n",
       " '(2009)',\n",
       " '(2021)',\n",
       " '(2010)',\n",
       " '(2017)',\n",
       " '(2010)',\n",
       " '(2017)',\n",
       " '(2003)',\n",
       " '(2011)',\n",
       " '(2017)',\n",
       " '(2007)',\n",
       " '(2015)',\n",
       " '(2017)',\n",
       " '(2020)',\n",
       " '(2021)',\n",
       " '(2019)',\n",
       " '(2012)',\n",
       " '(2020)',\n",
       " '(1958)',\n",
       " '(1997)',\n",
       " '(2018)',\n",
       " '(1988)',\n",
       " '(2010)',\n",
       " '(2011)',\n",
       " '(2015)',\n",
       " '(2013)',\n",
       " '(2015)',\n",
       " '(2015)',\n",
       " '(2012)',\n",
       " '(2010)',\n",
       " '(2021)',\n",
       " '(2006)',\n",
       " '(2016)',\n",
       " '(2016)',\n",
       " '(2012)',\n",
       " '(2004)',\n",
       " '(2017)',\n",
       " '(2013)',\n",
       " '(2007)',\n",
       " '(2018)',\n",
       " '(2016)',\n",
       " '(2003)',\n",
       " '(2003)',\n",
       " '(2000)',\n",
       " '(2013)',\n",
       " '(2019)',\n",
       " '(2020)',\n",
       " '(2006)',\n",
       " '(2004)',\n",
       " '(2013)',\n",
       " '(2009)',\n",
       " '(2017)',\n",
       " '(2017)',\n",
       " '(2003)',\n",
       " '(2006)',\n",
       " '(2014)',\n",
       " '(2012)',\n",
       " '(1957)',\n",
       " '(2022)',\n",
       " '(2012)',\n",
       " '(2004)',\n",
       " '(2008)',\n",
       " '(1987)',\n",
       " '(2021)',\n",
       " '(2016)',\n",
       " '(2011)',\n",
       " '(2001)',\n",
       " '(2004)',\n",
       " '(2021)',\n",
       " '(2015)',\n",
       " '(2019)',\n",
       " '(2007)',\n",
       " '(2014)',\n",
       " '(2008)',\n",
       " '(2018)',\n",
       " '(2019)',\n",
       " '(2020)',\n",
       " '(1999)',\n",
       " '(2013)',\n",
       " '(1996)',\n",
       " '(2021)',\n",
       " '(2010)',\n",
       " '(1978)',\n",
       " '(2015)',\n",
       " '(2015)',\n",
       " '(2018)',\n",
       " '(2011)',\n",
       " '(2007)',\n",
       " '(2016)',\n",
       " '(2020)',\n",
       " '(2016)',\n",
       " '(2014)',\n",
       " '(2008)',\n",
       " '(2011)',\n",
       " '(2004)',\n",
       " '(2001)',\n",
       " '(2012)',\n",
       " '(2017)',\n",
       " '(2008)']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_year=[]\n",
    "\n",
    "for i in soup.find_all('span',class_=\"secondaryInfo\"):\n",
    "    r_year.append(i.text.replace(\"\\n\",\" \"))\n",
    "    \n",
    "r_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7775143c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Movienames</th>\n",
       "      <th>Movieratings</th>\n",
       "      <th>release_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.       Jai Bhim (2021)</td>\n",
       "      <td>8.4</td>\n",
       "      <td>(2021)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.       Anbe Sivam (2003)</td>\n",
       "      <td>8.4</td>\n",
       "      <td>(2003)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.       K.G.F: Chapter 2 (2022)</td>\n",
       "      <td>8.4</td>\n",
       "      <td>(2022)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.       Golmaal (1979)</td>\n",
       "      <td>8.4</td>\n",
       "      <td>(1979)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.       Nayakan (1987)</td>\n",
       "      <td>8.4</td>\n",
       "      <td>(1987)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>246.       Arya (2004)</td>\n",
       "      <td>7.6</td>\n",
       "      <td>(2004)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>247.       Samsara (2001)</td>\n",
       "      <td>7.6</td>\n",
       "      <td>(2001)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>248.       Eega (2012)</td>\n",
       "      <td>7.6</td>\n",
       "      <td>(2012)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>249.       Newton (2017)</td>\n",
       "      <td>7.6</td>\n",
       "      <td>(2017)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>250.       Mumbai Meri Jaan (2008)</td>\n",
       "      <td>7.6</td>\n",
       "      <td>(2008)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>250 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Movienames Movieratings release_year\n",
       "0                     1.       Jai Bhim (2021)          8.4        (2021)\n",
       "1                   2.       Anbe Sivam (2003)          8.4        (2003)\n",
       "2             3.       K.G.F: Chapter 2 (2022)          8.4        (2022)\n",
       "3                      4.       Golmaal (1979)          8.4        (1979)\n",
       "4                      5.       Nayakan (1987)          8.4        (1987)\n",
       "..                                          ...          ...          ...\n",
       "245                     246.       Arya (2004)          7.6        (2004)\n",
       "246                  247.       Samsara (2001)          7.6        (2001)\n",
       "247                     248.       Eega (2012)          7.6        (2012)\n",
       "248                   249.       Newton (2017)          7.6        (2017)\n",
       "249         250.       Mumbai Meri Jaan (2008)          7.6        (2008)\n",
       "\n",
       "[250 rows x 3 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Making data frame\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({'Movienames':allmovie,'Movieratings':movierating,'release_year':r_year})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd9eac3",
   "metadata": {},
   "source": [
    "# 4) Write a python program to scrape product name, price and discounts from https://meesho.com/bags\u0002ladies/pl/p7vbp\n",
    "\n",
    "## Ans  ↓↓↓"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d1086e93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page = requests.get('https://meesho.com/bags-ladies/pl/p7vbp')\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "10cf67c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<p class=\"Text__StyledText-sc-oo0kvp-0 bWSOET NewProductCard__ProductTitle_Desktop-sc-j0e7tu-4 cQhePS NewProductCard__ProductTitle_Desktop-sc-j0e7tu-4 cQhePS\" color=\"greyT2\" font-size=\"16px\" font-weight=\"book\">Ravishing Alluring Women Handbags</p>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product_name = soup.find('p',class_=\"Text__StyledText-sc-oo0kvp-0 bWSOET NewProductCard__ProductTitle_Desktop-sc-j0e7tu-4 cQhePS NewProductCard__ProductTitle_Desktop-sc-j0e7tu-4 cQhePS\")\n",
    "product_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "668dd634",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ravishing Alluring Women Handbags'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product_name = soup.find('p',class_=\"Text__StyledText-sc-oo0kvp-0 bWSOET NewProductCard__ProductTitle_Desktop-sc-j0e7tu-4 cQhePS NewProductCard__ProductTitle_Desktop-sc-j0e7tu-4 cQhePS\")\n",
    "product_name.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "277a3b27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ravishing Alluring Women Handbags',\n",
       " 'Graceful Fancy Women Handbags',\n",
       " 'Ravishing Classy Women Handbags',\n",
       " 'Classic Versatile Women Handbags',\n",
       " 'Voguish Fancy Women Handbags',\n",
       " 'Graceful Versatile Women Handbags',\n",
       " 'Classic Stylish Women Handbags',\n",
       " 'Ravishing Fashionable Women Handbags',\n",
       " 'Elegant Classy Women Handbags',\n",
       " 'Elegant Alluring Women Handbags',\n",
       " 'Classic Alluring Women Handbags',\n",
       " 'Elegant Fashionable Women Handbags',\n",
       " 'Trendy Alluring Women Handbags',\n",
       " 'Trendy Alluring Women Handbags',\n",
       " 'Classic Fancy Women Handbags',\n",
       " 'Classic Fashionable Women Handbags']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_product=[]\n",
    "\n",
    "for i in soup.find_all('p',class_=\"Text__StyledText-sc-oo0kvp-0 bWSOET NewProductCard__ProductTitle_Desktop-sc-j0e7tu-4 cQhePS NewProductCard__ProductTitle_Desktop-sc-j0e7tu-4 cQhePS\"):\n",
    "    all_product.append(i.text)\n",
    "                       \n",
    "all_product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "17960f1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<h5 class=\"Text__StyledText-sc-oo0kvp-0 hiHdyy\" color=\"greyBase\" font-size=\"24px\" font-weight=\"bold\">₹<!-- -->384</h5>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price_of_bag = soup.find('h5',class_=\"Text__StyledText-sc-oo0kvp-0 hiHdyy\")\n",
    "price_of_bag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "102a1841",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'₹384'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price_of_bag = soup.find('h5',class_=\"Text__StyledText-sc-oo0kvp-0 hiHdyy\")\n",
    "price_of_bag.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "13fec99b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['₹384',\n",
       " '₹528',\n",
       " '₹950',\n",
       " '₹950',\n",
       " '₹1549',\n",
       " '₹950',\n",
       " '₹3202',\n",
       " '₹316',\n",
       " '₹950',\n",
       " '₹2337',\n",
       " '₹518',\n",
       " '₹725',\n",
       " '₹1320',\n",
       " '₹950',\n",
       " '₹646',\n",
       " '₹620']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_product_price=[]\n",
    "\n",
    "for i in soup.find_all('h5',class_=\"Text__StyledText-sc-oo0kvp-0 hiHdyy\"):\n",
    "    all_product_price.append(i.text)\n",
    "    \n",
    "all_product_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8bc62c23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<span class=\"Text__StyledText-sc-oo0kvp-0 lnonyH\" color=\"greenBase\" font-size=\"16px\" font-weight=\"demi\">12<!-- -->% off</span>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discount = soup.find('span',class_=\"Text__StyledText-sc-oo0kvp-0 lnonyH\")\n",
    "discount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f0c6f60f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'12% off'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discount = soup.find('span',class_=\"Text__StyledText-sc-oo0kvp-0 lnonyH\")\n",
    "discount.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bab0357d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['12% off',\n",
       " '9% off',\n",
       " '5% off',\n",
       " '5% off',\n",
       " '3% off',\n",
       " '5% off',\n",
       " '2% off',\n",
       " '14% off',\n",
       " '5% off',\n",
       " '2% off',\n",
       " '9% off',\n",
       " '6% off',\n",
       " '4% off',\n",
       " '5% off',\n",
       " '7% off',\n",
       " '7% off']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_product_discount=[]\n",
    "\n",
    "for i in soup.find_all('span',class_=\"Text__StyledText-sc-oo0kvp-0 lnonyH\"):\n",
    "    all_product_discount.append(i.text)\n",
    "    \n",
    "all_product_discount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ed939ecd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product_Name</th>\n",
       "      <th>Price_of_bag</th>\n",
       "      <th>Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ravishing Alluring Women Handbags</td>\n",
       "      <td>₹384</td>\n",
       "      <td>12% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Graceful Fancy Women Handbags</td>\n",
       "      <td>₹528</td>\n",
       "      <td>9% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ravishing Classy Women Handbags</td>\n",
       "      <td>₹950</td>\n",
       "      <td>5% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Classic Versatile Women Handbags</td>\n",
       "      <td>₹950</td>\n",
       "      <td>5% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Voguish Fancy Women Handbags</td>\n",
       "      <td>₹1549</td>\n",
       "      <td>3% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Graceful Versatile Women Handbags</td>\n",
       "      <td>₹950</td>\n",
       "      <td>5% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Classic Stylish Women Handbags</td>\n",
       "      <td>₹3202</td>\n",
       "      <td>2% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Ravishing Fashionable Women Handbags</td>\n",
       "      <td>₹316</td>\n",
       "      <td>14% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Elegant Classy Women Handbags</td>\n",
       "      <td>₹950</td>\n",
       "      <td>5% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Elegant Alluring Women Handbags</td>\n",
       "      <td>₹2337</td>\n",
       "      <td>2% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Classic Alluring Women Handbags</td>\n",
       "      <td>₹518</td>\n",
       "      <td>9% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Elegant Fashionable Women Handbags</td>\n",
       "      <td>₹725</td>\n",
       "      <td>6% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Trendy Alluring Women Handbags</td>\n",
       "      <td>₹1320</td>\n",
       "      <td>4% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Trendy Alluring Women Handbags</td>\n",
       "      <td>₹950</td>\n",
       "      <td>5% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Classic Fancy Women Handbags</td>\n",
       "      <td>₹646</td>\n",
       "      <td>7% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Classic Fashionable Women Handbags</td>\n",
       "      <td>₹620</td>\n",
       "      <td>7% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Product_Name Price_of_bag Discount\n",
       "0      Ravishing Alluring Women Handbags         ₹384  12% off\n",
       "1          Graceful Fancy Women Handbags         ₹528   9% off\n",
       "2        Ravishing Classy Women Handbags         ₹950   5% off\n",
       "3       Classic Versatile Women Handbags         ₹950   5% off\n",
       "4           Voguish Fancy Women Handbags        ₹1549   3% off\n",
       "5      Graceful Versatile Women Handbags         ₹950   5% off\n",
       "6         Classic Stylish Women Handbags        ₹3202   2% off\n",
       "7   Ravishing Fashionable Women Handbags         ₹316  14% off\n",
       "8          Elegant Classy Women Handbags         ₹950   5% off\n",
       "9        Elegant Alluring Women Handbags        ₹2337   2% off\n",
       "10       Classic Alluring Women Handbags         ₹518   9% off\n",
       "11    Elegant Fashionable Women Handbags         ₹725   6% off\n",
       "12        Trendy Alluring Women Handbags        ₹1320   4% off\n",
       "13        Trendy Alluring Women Handbags         ₹950   5% off\n",
       "14          Classic Fancy Women Handbags         ₹646   7% off\n",
       "15    Classic Fashionable Women Handbags         ₹620   7% off"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Making data frame\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({'Product_Name':all_product,'Price_of_bag':all_product_price ,'Discount':all_product_discount})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "042f4774",
   "metadata": {},
   "source": [
    "# 7 ) Write a python program to scrape details of all the posts from coreyms.com. Scrape the heading, date, content and the code for the video from the link for the youtube video from the post.\n",
    "\n",
    "## Ans  ↓↓↓"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c9a4f522",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page = requests.get('https://coreyms.com')\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5211311d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<h2 class=\"entry-title\" itemprop=\"headline\"><a class=\"entry-title-link\" href=\"https://coreyms.com/development/python/python-tutorial-zip-files-creating-and-extracting-zip-archives\" rel=\"bookmark\">Python Tutorial: Zip Files – Creating and Extracting Zip Archives</a></h2>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heading= soup.find('h2',class_=\"entry-title\")\n",
    "heading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "de144b35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Python Tutorial: Zip Files – Creating and Extracting Zip Archives'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heading.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "febb19e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Python Tutorial: Zip Files – Creating and Extracting Zip Archives',\n",
       " 'Python Data Science Tutorial: Analyzing the 2019 Stack Overflow Developer Survey',\n",
       " 'Python Multiprocessing Tutorial: Run Code in Parallel Using the Multiprocessing Module',\n",
       " 'Python Threading Tutorial: Run Code Concurrently Using the Threading Module',\n",
       " 'Update (2019-09-03)',\n",
       " 'Python Quick Tip: The Difference Between “==” and “is” (Equality vs Identity)',\n",
       " 'Python Tutorial: Calling External Commands Using the Subprocess Module',\n",
       " 'Visual Studio Code (Windows) – Setting up a Python Development Environment and Complete Overview',\n",
       " 'Visual Studio Code (Mac) – Setting up a Python Development Environment and Complete Overview',\n",
       " 'Clarifying the Issues with Mutable Default Arguments']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heading=[]\n",
    "\n",
    "for i in soup.find_all('h2',class_=\"entry-title\"):\n",
    "    heading.append(i.text)\n",
    "    \n",
    "heading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "de39a739",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<time class=\"entry-time\" datetime=\"2019-11-19T13:02:37-05:00\" itemprop=\"datePublished\">November 19, 2019</time>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_time= soup.find('time',class_=\"entry-time\")\n",
    "date_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b7c14dc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'November 19, 2019'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_time.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c739412e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['November 19, 2019',\n",
       " 'October 17, 2019',\n",
       " 'September 21, 2019',\n",
       " 'September 12, 2019',\n",
       " 'September 3, 2019',\n",
       " 'August 6, 2019',\n",
       " 'July 24, 2019',\n",
       " 'May 1, 2019',\n",
       " 'May 1, 2019',\n",
       " 'April 24, 2019']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_time=[]\n",
    "\n",
    "for i in soup.find_all('time',class_=\"entry-time\"):\n",
    "    date_time.append(i.text)\n",
    "    \n",
    "date_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7929cf44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<div class=\"entry-content\" itemprop=\"text\">\n",
       "<p>In this video, we will be learning how to create and extract zip archives. We will start by using the zipfile module, and then we will see how to do this using the shutil module. We will learn how to do this with single files and directories, as well as learning how to use gzip as well. Let’s get started…<br/></p>\n",
       "<span class=\"embed-youtube\" style=\"text-align:center; display: block;\"><iframe allowfullscreen=\"true\" class=\"youtube-player\" height=\"360\" sandbox=\"allow-scripts allow-same-origin allow-popups allow-presentation\" src=\"https://www.youtube.com/embed/z0gguhEmWiY?version=3&amp;rel=1&amp;showsearch=0&amp;showinfo=1&amp;iv_load_policy=1&amp;fs=1&amp;hl=en-US&amp;autohide=2&amp;wmode=transparent\" style=\"border:0;\" width=\"640\"></iframe></span>\n",
       "</div>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content= soup.find('div',class_=\"entry-content\")\n",
    "content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e44d6929",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' In this video, we will be learning how to create and extract zip archives. We will start by using the zipfile module, and then we will see how to do this using the shutil module. We will learn how to do this with single files and directories, as well as learning how to use gzip as well. Let’s get started…  '"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content.text.replace(\"\\n\",\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "be477f4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' In this video, we will be learning how to create and extract zip archives. We will start by using the zipfile module, and then we will see how to do this using the shutil module. We will learn how to do this with single files and directories, as well as learning how to use gzip as well. Let’s get started…  ',\n",
       " ' In this Python Programming video, we will be learning how to download and analyze real-world data from the 2019 Stack Overflow Developer Survey. This is terrific practice for anyone getting into the data science field. We will learn different ways to analyze this data and also some best practices. Let’s get started…    ',\n",
       " ' In this Python Programming video, we will be learning how to run code in parallel using the multiprocessing module. We will also look at how to process multiple high-resolution images at the same time using a ProcessPoolExecutor from the concurrent.futures module. Let’s get started…    ',\n",
       " ' In this Python Programming video, we will be learning how to run threads concurrently using the threading module. We will also look at how to download multiple high-resolution images online using a ThreadPoolExecutor from the concurrent.futures module. Let’s get started…    ',\n",
       " ' Hey everyone. I wanted to give you an update on my videos. I will be releasing videos on threading and multiprocessing within the next week. Thanks so much for your patience. I currently have a temporary recording studio setup at my Airbnb that will allow me to record and edit the threading/multiprocessing videos. I am going to be moving into my new house in 10 days and once I have my recording studio setup then you can expect much faster video releases. I really appreciate how patient everyone has been while I go through this move, especially those of you who are contributing monthly through YouTube  ',\n",
       " ' In this Python Programming Tutorial, we will be learning the difference between using “==” and the “is” keyword when doing comparisons. The difference between these is that “==” checks to see if values are equal, and the “is” keyword checks their identity, which means it’s going to check if the values are identical in terms of being the same object in memory. We’ll learn more in the video. Let’s get started…    ',\n",
       " ' In this Python Programming Tutorial, we will be learning how to run external commands using the subprocess module from the standard library. We will learn how to run commands, capture the output, handle errors, and also how to pipe output into other commands. Let’s get started…    ',\n",
       " ' In this Python Programming Tutorial, we will be learning how to set up a Python development environment in VSCode on Windows. VSCode is a very nice free editor for writing Python applications and many developers are now switching over to this editor. In this video, we will learn how to install VSCode, get the Python extension installed, how to change Python interpreters, create virtual environments, format/lint our code, how to use Git within VSCode, how to debug our programs, how unit testing works, and more. We have a lot to cover, so let’s go ahead and get started… VSCode on MacOS – https://youtu.be/06I63_p-2A4 Timestamps for topics in this tutorial: Installation – 1:13 Python Extension – 5:48 Switching Interpreters – 10:04 Changing Color Themes – 12:35 VSCode Settings – 16:16 Set Default Python – 21:33 Using Virtual Environments – 25:10 IntelliSense – 29:45 Code Formatting – 32:13 Code Linting – 37:06 Code Runner Extension – 39:42 Git Integration – 47:44 Use Different Terminal – 51:07 Debugging – 58:45 Unit Testing – 1:03:25 Zen Mode – 1:09:55    ',\n",
       " ' In this Python Programming Tutorial, we will be learning how to set up a Python development environment in VSCode on MacOS. VSCode is a very nice free editor for writing Python applications and many developers are now switching over to this editor. In this video, we will learn how to install VSCode, get the Python extension installed, how to change Python interpreters, create virtual environments, format/lint our code, how to use Git within VSCode, how to debug our programs, how unit testing works, and more. We have a lot to cover, so let’s go ahead and get started… VSCode on Windows – https://youtu.be/-nh9rCzPJ20 Timestamps for topics in this tutorial: Installation – 1:11 Python Extension – 6:21 Switching Interpreters – 10:16 Changing Color Themes – 13:08 VSCode Settings – 17:12 Set Default Python – 22:24 Using Virtual Environments – 25:52 IntelliSense – 30:28 Code Formatting – 33:08 Code Linting – 38:01 Code Runner Extension – 40:45 Git Integration – 49:05 Debugging – 58:15 Unit Testing – 1:02:38 Zen Mode – 1:10:42     ',\n",
       " ' In this Python Programming Tutorial, we will be clarifying the issues with mutable default arguments. We discussed this in my last video titled “5 Common Python Mistakes and How to Fix Them”, but I received many comments from people who were still confused. So we will be doing a deeper dive to explain exactly what is going on here. Let’s get started…    ']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content=[]\n",
    "\n",
    "for i in soup.find_all('div',class_=\"entry-content\"):\n",
    "    content.append(i.text.replace(\"\\n\",\" \"))\n",
    "    \n",
    "content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "18afd338",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headings</th>\n",
       "      <th>Date_Time</th>\n",
       "      <th>Contents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Python Tutorial: Zip Files – Creating and Extr...</td>\n",
       "      <td>November 19, 2019</td>\n",
       "      <td>In this video, we will be learning how to cre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Python Data Science Tutorial: Analyzing the 20...</td>\n",
       "      <td>October 17, 2019</td>\n",
       "      <td>In this Python Programming video, we will be ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Python Multiprocessing Tutorial: Run Code in P...</td>\n",
       "      <td>September 21, 2019</td>\n",
       "      <td>In this Python Programming video, we will be ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Python Threading Tutorial: Run Code Concurrent...</td>\n",
       "      <td>September 12, 2019</td>\n",
       "      <td>In this Python Programming video, we will be ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Update (2019-09-03)</td>\n",
       "      <td>September 3, 2019</td>\n",
       "      <td>Hey everyone. I wanted to give you an update ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Python Quick Tip: The Difference Between “==” ...</td>\n",
       "      <td>August 6, 2019</td>\n",
       "      <td>In this Python Programming Tutorial, we will ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Python Tutorial: Calling External Commands Usi...</td>\n",
       "      <td>July 24, 2019</td>\n",
       "      <td>In this Python Programming Tutorial, we will ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Visual Studio Code (Windows) – Setting up a Py...</td>\n",
       "      <td>May 1, 2019</td>\n",
       "      <td>In this Python Programming Tutorial, we will ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Visual Studio Code (Mac) – Setting up a Python...</td>\n",
       "      <td>May 1, 2019</td>\n",
       "      <td>In this Python Programming Tutorial, we will ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Clarifying the Issues with Mutable Default Arg...</td>\n",
       "      <td>April 24, 2019</td>\n",
       "      <td>In this Python Programming Tutorial, we will ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Headings           Date_Time  \\\n",
       "0  Python Tutorial: Zip Files – Creating and Extr...   November 19, 2019   \n",
       "1  Python Data Science Tutorial: Analyzing the 20...    October 17, 2019   \n",
       "2  Python Multiprocessing Tutorial: Run Code in P...  September 21, 2019   \n",
       "3  Python Threading Tutorial: Run Code Concurrent...  September 12, 2019   \n",
       "4                                Update (2019-09-03)   September 3, 2019   \n",
       "5  Python Quick Tip: The Difference Between “==” ...      August 6, 2019   \n",
       "6  Python Tutorial: Calling External Commands Usi...       July 24, 2019   \n",
       "7  Visual Studio Code (Windows) – Setting up a Py...         May 1, 2019   \n",
       "8  Visual Studio Code (Mac) – Setting up a Python...         May 1, 2019   \n",
       "9  Clarifying the Issues with Mutable Default Arg...      April 24, 2019   \n",
       "\n",
       "                                            Contents  \n",
       "0   In this video, we will be learning how to cre...  \n",
       "1   In this Python Programming video, we will be ...  \n",
       "2   In this Python Programming video, we will be ...  \n",
       "3   In this Python Programming video, we will be ...  \n",
       "4   Hey everyone. I wanted to give you an update ...  \n",
       "5   In this Python Programming Tutorial, we will ...  \n",
       "6   In this Python Programming Tutorial, we will ...  \n",
       "7   In this Python Programming Tutorial, we will ...  \n",
       "8   In this Python Programming Tutorial, we will ...  \n",
       "9   In this Python Programming Tutorial, we will ...  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Making data frame\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({'Headings':heading,'Date_Time' : date_time ,'Contents':content})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af4dcdb",
   "metadata": {},
   "source": [
    "# 10) Write a python program to scrape first 10 product details which include product name , price , Image URL from\n",
    "https://www.bewakoof.com/women-tshirts?ga_q=tshirts .\n",
    "\n",
    "Ans ↓↓↓"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d519f6f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page2 = requests.get('https://www.bewakoof.com/women-clothing')\n",
    "page2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "afb92a2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<div class=\"productCardDetail\"><div><h3 id=\"\">Women's Delete My Fat Hoodie</h3></div><div class=\"productPriceBox clearfix\"><span class=\"discountedPriceText\">₹ <b>799</b></span><span class=\"actualPriceText\">1549</span><span class=\"sellingFastBox\"></span><div class=\"loyaltyPriceBox\"><h6><b>₹<!-- -->749</b>For TriBe Members</h6></div> </div></div>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product_name = soup.find('div',class_=\"productCardDetail\")\n",
    "product_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a0228389",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Women's Delete My Fat Hoodie₹ 7991549₹749For TriBe Members \""
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product_name.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6218d8b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Women's Delete My Fat Hoodie₹ 7991549₹749For TriBe Members \",\n",
       " \"Women's Dog Hoodie₹ 8491549₹799For TriBe Members \",\n",
       " 'Padded Non Wired Full Cup T Shirt Bra In Off White₹ 5151199₹489For TriBe Members ',\n",
       " \"Women's Self Love Hoodie₹ 7991549₹749For TriBe Members \",\n",
       " 'Low Waist Heart Print Bikini Panty In Pink₹ 244499FEW LEFT₹219For TriBe Members ',\n",
       " 'Low Waist Floral Print Bikini Panty In Light Blue₹ 244499FEW LEFT₹219For TriBe Members ',\n",
       " 'Lightly Padded Non Wired Prined T-Shirt Bra In Blue₹ 5871199₹549For TriBe Members ',\n",
       " \"Women's Let Them Talk Hoodie₹ 8491549₹799For TriBe Members \",\n",
       " \"Women's You Are Enough Hoodie₹ 7991549₹749For TriBe Members \",\n",
       " 'Brush Stroke Whatever Round Neck 3/4 Sleeve T-Shirt Meteor Grey₹ 249499FEW LEFT₹229For TriBe Members ']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product_name=[]\n",
    "\n",
    "for i in soup.find_all('div',class_=\"productCardDetail\"):\n",
    "    product_name.append(i.text)\n",
    "    \n",
    "product_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b013adfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<span class=\"discountedPriceText\">₹ <b>799</b></span>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price = soup.find('span',class_=\"discountedPriceText\")\n",
    "price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "24b0115d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'₹ 799'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "cdd69e42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['₹ 799',\n",
       " '₹ 849',\n",
       " '₹ 515',\n",
       " '₹ 799',\n",
       " '₹ 244',\n",
       " '₹ 244',\n",
       " '₹ 587',\n",
       " '₹ 849',\n",
       " '₹ 799',\n",
       " '₹ 249']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price=[]\n",
    "\n",
    "for i in soup.find_all('span',class_=\"discountedPriceText\"):\n",
    "    price.append(i.text)\n",
    "    \n",
    "price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "64f835f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c5971e7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://images.bewakoof.com/t320/women-s-delete-my-fat-hoodie-hoodies-406702-1633079171.jpg\n",
      "\n",
      "https://images.bewakoof.com/t320/women-s-dog-hoodie-hoodies-406712-1633079165.jpg\n",
      "\n",
      "https://images.bewakoof.com/t320/clovia-padded-non-wired-full-cup-t-shirt-bra-in-off-white-clovia-women-s-bra-fits-like-a-second-skin01-356185-1620651625.jpg\n",
      "\n",
      "https://images.bewakoof.com/t320/women-s-self-love-hoodie-hoodies-406704-1633079166.jpg\n",
      "\n",
      "https://images.bewakoof.com/t320/clovia-low-waist-heart-print-bikini-panty-in-pink-bikini-382740-1626879862.jpg\n",
      "\n",
      "https://images.bewakoof.com/t320/clovia-low-waist-floral-print-bikini-panty-in-light-blue-bikini-382742-1626879880.jpg\n",
      "\n",
      "https://images.bewakoof.com/t320/clovia-lightly-padded-non-wired-prined-t-shirt-bra-in-blue-clovia-women-s-bra-fits-like-a-second-skin01-356183-1620651532.jpg\n",
      "\n",
      "https://images.bewakoof.com/t320/women-s-let-them-talk-hoodie-hoodies-406714-1633079173.jpg\n",
      "\n",
      "https://images.bewakoof.com/t320/women-s-you-are-enough-hoodie-hoodies-406718-1633079199.jpg\n",
      "\n",
      "https://images.bewakoof.com/t320/brush-stroke-whatever-round-neck-3-4-sleeve-t-shirt-meteor-grey-282269-1638214040-1.jpg\n",
      "\n"
     ]
    }
   ],
   "source": [
    "html = urlopen('https://www.bewakoof.com/women-clothing')\n",
    "bs = BeautifulSoup(html, 'html.parser')\n",
    "images = bs.find_all('img', {'src':re.compile('.jpg')})\n",
    "for image in images: \n",
    "    print(image['src']+'\\n')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "10e4c07f",
   "metadata": {},
   "source": [
    "# I am not able to extract the data from this web page for question no. 9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdceef6e",
   "metadata": {},
   "source": [
    "# 8) Write a python program to scrape house details from mentioned URL. It should include house title, location,area, EMI and price from https://www.nobroker.in/ .Enter three localities which are Indira Nagar, Jayanagar, Rajaji Nagar.\n",
    "\n",
    "\n",
    "## Ans  ↓↓↓\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d011c6f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page3 = requests.get('https://www.nobroker.in/property/sale/bangalore/multiple?searchParam=W3sibGF0IjoxMi45NzgzNjkyLCJsb24iOjc3LjY0MDgzNTYsInBsYWNlSWQiOiJDaElKa1FOM0dLUVdyanNSTmhCUUpyaEdEN1UiLCJwbGFjZU5hbWUiOiJJbmRpcmFuYWdhciJ9LHsibGF0IjoxMi45MzA3NzM1LCJsb24iOjc3LjU4MzgzMDIsInBsYWNlSWQiOiJDaElKMmRkbFo1Z1ZyanNSaDFCT0FhZi1vcnMiLCJwbGFjZU5hbWUiOiJKYXlhbmFnYXIifSx7ImxhdCI6MTIuOTk4MTczMiwibG9uIjo3Ny41NTMwNDQ1OTk5OTk5OSwicGxhY2VJZCI6IkNoSUp4Zlc0RFBNOXJqc1JLc05URy01cF9RUSIsInBsYWNlTmFtZSI6IlJhamFqaW5hZ2FyIn1d&radius=2.0&city=bangalore&locality=Indiranagar,&locality=Jayanagar,&locality=Rajajinagar')\n",
    "page3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "826b4fe1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<span class=\"overflow-hidden overflow-ellipsis whitespace-nowrap max-w-80pe po:max-w-full\">4+ BHK In Independent House  For Sale  In Rajajinagar</span>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "house = soup.find('span',class_=\"overflow-hidden overflow-ellipsis whitespace-nowrap max-w-80pe po:max-w-full\")\n",
    "house"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f286fb3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4+ BHK In Independent House  For Sale  In Rajajinagar'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "house.text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b791079d",
   "metadata": {},
   "source": [
    "# 5&6 Write a python program to scrape cricket rankings from icc-cricket.com.\n",
    "\n",
    "## Ans  ↓↓↓"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a71a9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7eed0e6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page4 = requests.get('https://www.icc-cricket.com/rankings/mens/team-rankings/odi')\n",
    "page4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "2bc6e74d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<span class=\"u-hide-phablet\">New Zealand</span>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "team_name = soup.find('span',class_=\"u-hide-phablet\")\n",
    "team_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "46eb083a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'New Zealand'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "team_name = soup.find('span',class_=\"u-hide-phablet\")\n",
    "team_name.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "4736810c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['New Zealand', 'England', 'Australia', 'India', 'South Africa', 'Pakistan', 'Bangladesh', 'Sri Lanka', 'West Indies', 'Afghanistan', 'Ireland', 'Scotland', 'Zimbabwe', 'Netherlands', 'UAE', 'Oman', 'Namibia', 'Nepal', 'United States', 'Papua New Guinea', '', '', '', '', '']\n"
     ]
    }
   ],
   "source": [
    "team_name=[]\n",
    "\n",
    "for i in soup.find_all('span',class_=\"u-hide-phablet\"):\n",
    "    team_name.append(i.text)\n",
    "    \n",
    "print(team_name)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "15d1dc56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['New Zealand',\n",
       " 'England',\n",
       " 'Australia',\n",
       " 'India',\n",
       " 'South Africa',\n",
       " 'Pakistan',\n",
       " 'Bangladesh',\n",
       " 'Sri Lanka',\n",
       " 'West Indies']"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=team_name[0:9]\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "07562453",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tr class=\"table-body\" data-team-id=\"11\">\n",
       "<td class=\"table-body__cell table-body__cell--position u-text-right\">2</td>\n",
       "<td class=\"table-body__cell rankings-table__team\">\n",
       "<span class=\"flag-15 table-body_logo ENG\"></span>\n",
       "<span class=\"u-hide-phablet\">England</span>\n",
       "<span class=\"u-show-phablet\">ENG</span>\n",
       "</td>\n",
       "<td class=\"table-body__cell u-center-text\">32</td>\n",
       "<td class=\"table-body__cell u-center-text\">3,793</td>\n",
       "<td class=\"table-body__cell u-text-right rating\">119</td>\n",
       "</tr>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table = soup.find('tr',class_=\"table-body\")\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "32189f4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' 2   England ENG  32 3,793 119 '"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table.text.replace(\"\\n\",\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "4b1a7975",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['  2      England  ENG    32  3,793  119  ',\n",
       " '  3      Australia  AUS    31  3,475  112  ',\n",
       " '  4      India  IND    38  4,162  110  ',\n",
       " '  5      South Africa  SA    31  3,167  102  ',\n",
       " '  6      Pakistan  PAK    30  2,921  97  ',\n",
       " '  7      Bangladesh  BAN    36  3,350  93  ',\n",
       " '  8      Sri Lanka  SL    35  2,835  81  ',\n",
       " '  9      West Indies  WI    36  2,788  77  ',\n",
       " '  10      Afghanistan  AFG    23  1,562  68  ',\n",
       " '  11      Ireland  IRE    28  1,445  52  ',\n",
       " '  12      Scotland  SCO    14  712  51  ',\n",
       " '  13      Zimbabwe  ZIM    23  951  41  ',\n",
       " '  14      Netherlands  NED    13  459  35  ',\n",
       " '  15      UAE  UAE    20  651  33  ',\n",
       " '  16      Oman  OMA    27  777  29  ',\n",
       " '  17      Namibia  NAM    13  268  21  ',\n",
       " '  18      Nepal  NEP    17  308  18  ',\n",
       " '  19      United States  USA    14  232  17  ',\n",
       " '  20      Papua New Guinea  PNG    23  178  8  ']"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table=[]\n",
    "\n",
    "for i in soup.find_all('tr',class_=\"table-body\"):\n",
    "    table.append(i.text.replace(\"\\n\",\"  \"))\n",
    "    \n",
    "table"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cff0cd31",
   "metadata": {},
   "source": [
    " I have some confusion to extract the data from this web page. In website, first row is in banner format and remaining all in \n",
    " table format. so i am not getting how to extract all data by using loop. Therfore, i have not completed this que. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
